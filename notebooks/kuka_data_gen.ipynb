{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "python_path = pathlib.Path('.').absolute().parent/'python'\n",
    "os.sys.path.insert(1, str(python_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is demo for kuka reaching a desired point with diff_qp\n",
    "## Author : Avadesh Meduri\n",
    "## Date : 25/02/2022\n",
    "import time\n",
    "import numpy as np\n",
    "import pinocchio as pin\n",
    "from robot_properties_kuka.config import IiwaConfig\n",
    "\n",
    "import meshcat\n",
    "import meshcat.transformations as tf\n",
    "import meshcat.geometry as g\n",
    "\n",
    "from vocam.diff_pin_costs import DiffFrameTranslationCost, DiffFrameVelocityCost\n",
    "from vocam.inverse_qp import IOC\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = IiwaConfig.buildRobotWrapper()\n",
    "model, data = robot.model, robot.data\n",
    "f_id = model.getFrameId(\"EE\")\n",
    "j_id = [f_id]\n",
    "for i in range(3, model.nq+1):\n",
    "    j_id.append(model.getFrameId(\"A\" + str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7001/static/\n"
     ]
    }
   ],
   "source": [
    "viz = pin.visualize.MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "viz.initViewer(open=False)\n",
    "viz.loadViewerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DiffFrameTranslationCost.apply\n",
    "dvc = DiffFrameVelocityCost.apply\n",
    "\n",
    "def quadratic_loss(q_pred, x_des, nq, n_col):\n",
    "    loss = 6.0e1*torch.linalg.norm(dtc(q_pred[-2*nq:], model, data, f_id) - x_des)\n",
    "    loss += 2.5e0*torch.linalg.norm(dvc(q_pred[-2*nq:], torch.zeros(nq), model, data, f_id)) # asking for zero velocity\n",
    "    loss += 1e-2*torch.linalg.norm(q_pred[-2*nq:-nq]) # joint regularization\n",
    "    \n",
    "    for i in range(n_col):    \n",
    "        loss += 2e0*torch.linalg.norm(dtc(q_pred[(3*i)*nq: (3*i+2)*nq], model, data, f_id) - x_des)\n",
    "        loss += 5e-1*torch.linalg.norm(dvc(q_pred[(3*i)*nq: (3*i+2)*nq], q_pred[(3*i+2)*nq:(3*i+3)*nq], model, data, f_id)) # asking for zero velocity\n",
    "        loss += 1e-2*torch.linalg.norm(q_pred[(3*i+2)*nq: (3*i+3)*nq]) # control regularization\n",
    "        loss += 2e-1*torch.linalg.norm(q_pred[(3*i+1)*nq: (3*i+2)*nq]) # velocity regularization\n",
    "        loss += 3e-3*torch.linalg.norm(q_pred[(3*i)*nq: (3*i+1)*nq]) # joint regularization\n",
    "        loss += 2e-3*torch.linalg.norm(q_pred[(3*i)*nq+3: (3*i+1)*nq])\n",
    "        loss += 4e-3*torch.linalg.norm(q_pred[(3*i)*nq+5])\n",
    "        \n",
    "        if i < n_col - 1:\n",
    "            loss += 5e-2*torch.linalg.norm(torch.subtract(q_pred[(3*i+2)*nq: (3*i+3)*nq], \\\n",
    "                                                          q_pred[(3*i+5)*nq: (3*i+6)*nq]))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstacle_loss(q_pred, x_des, nq, n_col, obs_pos_arr, obs_rad):\n",
    "    \n",
    "    loss = quadratic_loss(q_pred, x_des, nq, n_col)\n",
    "    \n",
    "    for k in range(len(obs_pos_arr)):\n",
    "        obs_pos = obs_pos_arr[k]\n",
    "        for i in range(len(j_id)):\n",
    "            dist_loss = torch.linalg.norm(dtc(q_pred[-2*nq:], model, data, j_id[i]) - obs_pos) \n",
    "            loss += 1.0e3*torch.exp(-(dist_loss-obs_rad)/0.01)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq = model.nq\n",
    "nv = model.nv\n",
    "q0 = [np.pi/16.0, -np.pi/16.0, 0, 0, 0, 0, 0]\n",
    "x_init = np.concatenate([q0, pin.utils.zero(model.nv)])\n",
    "\n",
    "n_col = 5\n",
    "u_max = [2.5,2.5,2.5, 1.5, 1.5, 1.5, 1.0]\n",
    "dt = 0.05\n",
    "\n",
    "isvec = True\n",
    "lr = 1e-1\n",
    "max_eps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_obstacles(viz, nb_balls, obs_rad):\n",
    "    r = 0.5\n",
    "    obs_pos_arr = []\n",
    "    for l in range(nb_balls):\n",
    "        theta = 0.0*np.pi*(np.random.rand(1) - 0.5) + 0.5*np.pi\n",
    "        ht = 0.0*np.random.rand(1) + 0.35\n",
    "        obs_pos = torch.squeeze(torch.tensor([r*np.sin(theta), r*np.cos(theta), ht]))\n",
    "        obs_pos_arr.append(obs_pos)\n",
    "        viz.viewer[\"obstacle_\" + str(l)].set_object(g.Sphere(obs_rad), \n",
    "                                 g.MeshLambertMaterial(\n",
    "                                     color=0x22ddff,\n",
    "                                     reflectivity=0.8))\n",
    "        viz.viewer[\"obstacle_\" + str(l)].set_transform(tf.translation_matrix(obs_pos.detach().numpy()))\n",
    "        \n",
    "    return obs_pos_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "f_name = \"15\"\n",
    "n_mpc = 20\n",
    "d_tol = 0.05 # how close the ee should be to the ball to be accepted as a good data point\n",
    "\n",
    "## for obstacles\n",
    "add_obstacles = True\n",
    "nb_balls = 1\n",
    "obs_rad = 0.15\n",
    "\n",
    "x_train = torch.zeros((1,len(x_init) + 3))\n",
    "x_train_tmp = torch.zeros((n_mpc,len(x_init) + 3))\n",
    "\n",
    "n_vars = 3*nq*n_col + 2*nq\n",
    "if not isvec:\n",
    "    y_train_tmp = torch.zeros((n_mpc, n_vars**2 + n_vars))\n",
    "else:\n",
    "    y_train_tmp = torch.zeros((n_mpc, 2*n_vars))\n",
    "\n",
    "q_des_arr = np.array([[2.1789238e-02,  3.3214998e-01, -1.4518893e-04, -8.7141126e-01,\n",
    "                          6.0329604e-01, -1.3965217e-03,  1.4794523e-04],\n",
    "                      [1.3737, 0.9711, 1.6139, 1.2188, 1.5669, 0.1236, 0.2565]])\n",
    "# x_des_arr = torch.tensor([[0.5, -0.4, 0.7], [0.6, 0.4, 0.5]])\n",
    "x_des_arr = torch.tensor([[0.3, -0.3, 0.7], [0.6, 0.2, 0.5]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :114/10000 Data Size is : 60 loss is : 0.668162\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     loss \u001b[38;5;241m=\u001b[39m quadratic_loss(x_pred, x_des, nq, n_col)\n\u001b[1;32m     58\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 59\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     61\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/function.py:243\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         backward_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    247\u001b[0m         vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mvjp  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(buffer_size):\n",
    "\n",
    "    if k % n_mpc == 0:\n",
    "        \n",
    "        ## Adding to data only if the kuka reaches the ball\n",
    "        if k > 0:\n",
    "            dist = torch.linalg.norm(dtc(x_pred[-2*nq:], model, data, f_id) - x_des)\n",
    "            if dist <= d_tol:\n",
    "                if len(x_train) != 1:\n",
    "                    x_train = torch.vstack((x_train, x_train_tmp))\n",
    "                    y_train = torch.vstack((y_train, y_train_tmp))                \n",
    "                elif len(x_train) == 1:\n",
    "                    x_train = x_train_tmp\n",
    "                    y_train = y_train_tmp\n",
    "                    \n",
    "                    x_train_tmp = torch.zeros_like(x_train_tmp)\n",
    "                    y_train_tmp = torch.zeros_like(y_train_tmp)\n",
    "                \n",
    "        r = 0.4*np.random.rand(1) +0.5\n",
    "        theta = 0.75*np.pi*(np.random.rand(1)) + 0.15*np.pi\n",
    "        x_des = torch.squeeze(torch.tensor([r*np.sin(theta), r*np.cos(theta), 0.45*np.random.rand(1)+0.15]))\n",
    "\n",
    "        viz.viewer[\"box\"].set_object(g.Sphere(0.05), \n",
    "                         g.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))\n",
    "        viz.viewer[\"box\"].set_transform(tf.translation_matrix(x_des.detach().numpy()))\n",
    "\n",
    "        if add_obstacles:\n",
    "            obs_pos = viz_obstacles(viz, nb_balls, obs_rad)\n",
    "        \n",
    "        if np.random.randint(3) == 0 or k == 0:\n",
    "            x_init = np.zeros(2*nq)\n",
    "            x_init[0:nq] = q_des_arr[0] + 0.3*2*(np.random.rand(nq) - 0.5)\n",
    "            x_init[0] -= 2*0.5*(np.random.rand(1) - 0.5)\n",
    "            x_init[2] -= 2*0.3*(np.random.rand(1) - 0.5)\n",
    "            x_init[nq:] = 0.7*2*(np.random.rand(nv) - 0.5)\n",
    "    \n",
    "    else:\n",
    "        x_init = x_pred_np[3*nq*(n_col-1):3*nq*(n_col-1) + 2*nq]\n",
    "            \n",
    "    i = 0\n",
    "    loss = 1000.\n",
    "    old_loss = 10000.\n",
    "\n",
    "    ioc = IOC(n_col, nq, u_max, dt, eps = 1.0, isvec=isvec)\n",
    "    optimizer = torch.optim.Adam(ioc.parameters(), lr=lr)\n",
    "    \n",
    "    while loss > 0.03 and i < max_eps and abs(old_loss - loss) > 5e-4:\n",
    "        x_pred = ioc(x_init) \n",
    "        old_loss = loss\n",
    "        if add_obstacles:\n",
    "            loss = obstacle_loss(x_pred, x_des, nq, n_col, obs_pos, obs_rad)\n",
    "        else:\n",
    "            loss = quadratic_loss(x_pred, x_des, nq, n_col)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "\n",
    "    print(\"Index :\" + str(k) + \"/\" + str(buffer_size) + \" Data Size is : \" + str(len(x_train))\\\n",
    "          + \" loss is : \" + str(np.round(loss.detach().numpy(),3)), end = '\\r', flush = True)\n",
    "    x_pred_np = ioc(x_init).detach().numpy()\n",
    "    \n",
    "    for i in range(n_col+1):\n",
    "        q = x_pred_np[3*nq*i:3*nq*i + nq]\n",
    "        dq = x_pred_np[3*nq*i + nq:3*nq*i + 2*nq]\n",
    "\n",
    "        pin.forwardKinematics(model, data, q, dq, np.zeros(nv))\n",
    "        pin.updateFramePlacements(model, data)\n",
    "\n",
    "        viz.display(q)\n",
    "        time.sleep(0.01)\n",
    "    \n",
    "    # storing x train\n",
    "    x_train_tmp[k % n_mpc][0:2*nq] = torch.tensor(x_init)\n",
    "    x_train_tmp[k % n_mpc][2*nq:] = x_des\n",
    "    \n",
    "    # storing the weights and x_nom\n",
    "    y_train_tmp[k % n_mpc] = torch.hstack((ioc.weight.flatten(), ioc.x_nom))\n",
    "\n",
    "    if k % 100 == 0 and k:\n",
    "        torch.save(x_train[0:k], \"../data/x_train\" + str(f_name) + \".pt\")\n",
    "        torch.save(y_train[0:k], \"../data/y_train\" + str(f_name) + \".pt\")\n",
    "\n",
    "torch.save(x_train, \"../data/x_train\" + str(f_name) + \".pt\")\n",
    "torch.save(y_train, \"../data/y_train\" + str(f_name) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(x_pred[2*nq + 1:: 3*nq], label = \"joint torque\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,0], label = \"x_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,1], label = \"y_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,2], label = \"z_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mim_data_utils import DataLogger, DataReader\n",
    "reader = DataReader('test.mds')\n",
    "\n",
    "for i in range(len(reader.data['joint_positions'])):\n",
    "    q = reader.data['joint_positions'][i]\n",
    "    viz.display(q)\n",
    "#     time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([10,20,30,40])\n",
    "b = np.array([5,4,3,2])\n",
    "a*b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
