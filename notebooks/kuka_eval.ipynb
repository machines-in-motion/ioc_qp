{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_path = pathlib.Path('.').absolute().parent/'python'\n",
    "os.sys.path.insert(1, str(python_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinocchio as pin\n",
    "from robot_properties_kuka.config import IiwaConfig\n",
    "\n",
    "import meshcat\n",
    "import meshcat.transformations as tf\n",
    "import meshcat.geometry as g\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import trange\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocam.qpnet import DataUtils, QPNet\n",
    "import vocam.qpnet\n",
    "from vocam.inverse_qp import IOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7003/static/\n"
     ]
    }
   ],
   "source": [
    "robot = IiwaConfig.buildRobotWrapper()\n",
    "model, data = robot.model, robot.data\n",
    "f_id = model.getFrameId(\"EE\")\n",
    "\n",
    "viz = pin.visualize.MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "viz.initViewer(open=False)\n",
    "viz.loadViewerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhjzhu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hz/Research/ioc_qp/notebooks/wandb/run-20220506_160528-x0vm7q4s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hjzhu/vocam/runs/x0vm7q4s\" target=\"_blank\">rural-wood-44</a></strong> to <a href=\"https://wandb.ai/hjzhu/vocam\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"vocam\", group=\"kuka_qpnet_eval\", entity=\"hjzhu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.nq = model.nq\n",
    "wandb.config.nv = model.nv\n",
    "\n",
    "wandb.config.n_col = 5\n",
    "wandb.config.u_max = [2.5, 2.5, 2.5, 1.5, 1.5, 1.5, 1.0]\n",
    "wandb.config.dt = 0.05\n",
    "\n",
    "wandb.config.n_vars = 3 * model.nq * wandb.config.n_col + 2 * model.nq\n",
    "wandb.config.isvec = True\n",
    "wandb.config.lr_qp = 1e-1\n",
    "wandb.config.max_it = 100\n",
    "wandb.config.task_horizon = 30\n",
    "\n",
    "wandb.config.input_size = model.nq + model.nv + 3\n",
    "wandb.config.output_size = 2 * wandb.config.n_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_artifacts = run.use_artifact('hjzhu/vocam/qpnet_datasets:latest', type='dataset')\n",
    "data_dir = data_artifacts.download()\n",
    "data_test = torch.load(data_dir + \"/data_20_40.pt\")\n",
    "unzipped = list(zip(*data_test))\n",
    "x_train = torch.vstack([*unzipped[0]]).to('cpu')\n",
    "y_train = torch.vstack([*unzipped[1]]).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QPNet(\n",
       "  (swish): SiLU()\n",
       "  (fc1): Linear(in_features=17, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (out): Linear(in_features=512, out_features=238, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = QPNet(wandb.config.input_size, \n",
    "                wandb.config.output_size).to('cpu')\n",
    "model_artifacts = run.use_artifact('hjzhu/vocam/qpnet_models:latest', type='model')\n",
    "model_dir = model_artifacts.download()\n",
    "network.load(model_dir + \"/qpnet_41.pt\")\n",
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq = wandb.config.nq\n",
    "nv = wandb.config.nv\n",
    "n_col = wandb.config.n_col\n",
    "u_max = wandb.config.u_max\n",
    "dt = wandb.config.dt\n",
    "isvec = wandb.config.isvec\n",
    "lr_qp = wandb.config.lr_qp\n",
    "n_vars = wandb.config.n_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "tensor([0.4058, 0.5138, 0.2468])\n"
     ]
    }
   ],
   "source": [
    "# visualize the init configuration and the desired location for a random data point\n",
    "k = 150\n",
    "x_in = x_train[k].clone().detach()\n",
    "y = y_train[k].clone().detach()\n",
    "\n",
    "q_init = x_in[:nq].numpy()\n",
    "x_des = x_in[-3:]\n",
    "\n",
    "print(k)\n",
    "print(x_des)\n",
    "\n",
    "viz.viewer[\"box\"].set_object(g.Sphere(0.05), \n",
    "                         g.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))\n",
    "viz.viewer[\"box\"].set_transform(tf.translation_matrix(x_des[-3:].detach().numpy()))\n",
    "viz.display(q_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddq = []\n",
    "for j in range(50):\n",
    "    ioc = IOC(n_col, nq, u_max, dt, eps = 1.0, isvec=isvec)\n",
    "    optimizer = torch.optim.Adam(ioc.parameters(), lr=lr_qp)\n",
    "    pred = network(x_in[None,:]).squeeze()\n",
    "    \n",
    "    if not isvec:\n",
    "        ioc.weight = torch.nn.Parameter(torch.reshape(pred[0:n_vars**2], (n_vars, n_vars)))\n",
    "        ioc.x_nom = torch.nn.Parameter(pred[n_vars**2:])\n",
    "    else:\n",
    "        ioc.weight = torch.nn.Parameter(pred[0:n_vars])\n",
    "        ioc.x_nom = torch.nn.Parameter(pred[n_vars:])\n",
    "        \n",
    "    x_pred = ioc((x_in[:-3]).detach().numpy()) \n",
    "    x_pred = x_pred.detach().numpy()\n",
    "    ddq.append(x_pred[2*nq:3*nq])\n",
    "\n",
    "    for i in range(n_col+1):\n",
    "        q = x_pred[3*nq*i:3*nq*i + nq]\n",
    "        dq = x_pred[3*nq*i + nq:3*nq*i + 2*nq]\n",
    "\n",
    "        pin.forwardKinematics(model, data, q, dq, np.zeros(nv))\n",
    "        pin.updateFramePlacements(model, data)\n",
    "\n",
    "        viz.display(q)\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    x_in[0:2*nq] = torch.tensor(x_pred[-2*nq:])\n",
    "    \n",
    "ddq = np.vstack(ddq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
