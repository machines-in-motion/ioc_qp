{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75e96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is demo for kuka reaching a desired point with diff_qp\n",
    "## Author : Avadesh Meduri\n",
    "## Date : 25/02/2022\n",
    "import time\n",
    "import numpy as np\n",
    "import pinocchio as pin\n",
    "from robot_properties_kuka.config import IiwaConfig\n",
    "\n",
    "import meshcat\n",
    "import meshcat.transformations as tf\n",
    "import meshcat.geometry as g\n",
    "\n",
    "from diff_pin_costs import DiffFrameTranslationCost\n",
    "from inverse_qp import IOC\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e67bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/openrobots/lib/python3.8/site-packages/pinocchio/shortcuts.py:45: UserWarning: You passed package dir(s) via argument geometry_model and provided package_dirs.\n",
      "  geom_model = pin.buildGeomFromUrdf(model, filename, geometry_type, package_dirs)\n"
     ]
    }
   ],
   "source": [
    "robot = IiwaConfig.buildRobotWrapper()\n",
    "model, data = robot.model, robot.data\n",
    "f_id = model.getFrameId(\"EE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f04e687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7003/static/\n"
     ]
    }
   ],
   "source": [
    "viz = pin.visualize.MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "viz.initViewer(open=False)\n",
    "viz.loadViewerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67693d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DiffFrameTranslationCost.apply\n",
    "\n",
    "def quadratic_loss(q_pred, x_des, nq, n_col):\n",
    "    loss = 1e2*torch.linalg.norm(dtc(q_pred[-2*nq:], model, data, f_id) - x_des)\n",
    "    loss += 5*torch.linalg.norm(q_pred[-nq:])\n",
    "    for i in range(n_col):    \n",
    "        loss += 0.8*torch.linalg.norm(dtc(q_pred[(3*i)*nq: (3*i+2)*nq], model, data, f_id) - x_des)\n",
    "        loss += 4e-3*torch.linalg.norm(q_pred[(3*i+2)*nq: (3*i+3)*nq]) # control regularization\n",
    "        loss += 2e-1*torch.linalg.norm(q_pred[(3*i+1)*nq: (3*i+2)*nq]) # velocity regularization\n",
    "        loss += 1e-1*torch.linalg.norm(q_pred[(3*i)*nq: (3*i+1)*nq]) # joint regularization\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f8db28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq = model.nq\n",
    "nv = model.nv\n",
    "q0 = [np.pi/16.0, -np.pi/16.0, 0, 0, 0, 0, 0]\n",
    "x_init = np.concatenate([q0, pin.utils.zero(model.nv)])\n",
    "\n",
    "n_col = 5\n",
    "u_max = [2.5,2.5,2.5, 1.5, 1.5, 1.5, 1.0]\n",
    "\n",
    "isvec = True\n",
    "lr = 1e-1\n",
    "max_eps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f7d8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 600\n",
    "\n",
    "x_train_init = torch.zeros((buffer_size,len(x_init)))\n",
    "x_train_des = torch.zeros((buffer_size, 3))\n",
    "\n",
    "n_vars = 3*nq*n_col + 2*nq\n",
    "if not isvec:\n",
    "    y_train = torch.zeros((buffer_size, n_vars**2 + n_vars))\n",
    "else:\n",
    "    y_train = torch.zeros((buffer_size, 2*n_vars))\n",
    "\n",
    "q_des_arr = np.array([[ 0.3009,  1.1532,  1.7729,  1.7383,  1.2195, -0.0204,  0.0593],\n",
    "                      [1.3737, 0.9711, 1.6139, 1.2188, 1.5669, 0.1236, 0.2565]])\n",
    "x_des_arr = torch.tensor([[0.5, -0.4, 0.4], [0.6, 0.4, 0.7]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c88cdfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :599/600 Iteration :25/100 loss is : 14.586541698343325\r"
     ]
    }
   ],
   "source": [
    "for k in range(buffer_size):\n",
    "    ioc = IOC(n_col, nq, u_max, 0.05, eps = 1.0, isvec=isvec)\n",
    "    optimizer = torch.optim.Adam(ioc.parameters(), lr=lr)\n",
    "\n",
    "    if k % 10 == 0:\n",
    "        \n",
    "        x_des = x_des_arr[np.random.randint(len(x_des_arr))]\n",
    "    \n",
    "        viz.viewer[\"box\"].set_object(g.Sphere(0.05), \n",
    "                         g.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))\n",
    "        viz.viewer[\"box\"].set_transform(tf.translation_matrix(x_des.detach().numpy()))\n",
    "\n",
    "        x_init = np.zeros(2*nq)\n",
    "        x_init[0:nq] = q_des_arr[np.random.randint(len(x_des_arr))] + 0.5*2*(np.random.rand(nq) - 0.5)\n",
    "        x_init[nq:] = 0.2*2*(np.random.rand(nv) - 0.5)\n",
    "    \n",
    "    else:\n",
    "        x_init = x_pred[-2*nq:]\n",
    "\n",
    "    x_train_init[k] = torch.tensor(x_init)\n",
    "    x_train_des[k] = x_des\n",
    "    \n",
    "    i = 0\n",
    "    loss = 1000.\n",
    "    old_loss = 10000.\n",
    "    \n",
    "    while loss > 0.03 and i < max_eps and abs(old_loss - loss) > 5e-4:\n",
    "        x_pred = ioc(x_init) \n",
    "        old_loss = loss\n",
    "        loss = quadratic_loss(x_pred, x_des, nq, n_col)\n",
    "        print(\"Index :\" + str(k) + \"/\" + str(buffer_size) + \" Iteration :\" + str(i) + \"/\" + str(max_eps) +  \" loss is : \" + str(loss.detach().numpy()), end = '\\r', flush = True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "    \n",
    "    x_pred = ioc(x_init).detach().numpy()\n",
    "    for i in range(n_col+1):\n",
    "        q = x_pred[3*nq*i:3*nq*i + nq]\n",
    "        dq = x_pred[3*nq*i + nq:3*nq*i + 2*nq]\n",
    "\n",
    "        pin.forwardKinematics(model, data, q, dq, np.zeros(nv))\n",
    "        pin.updateFramePlacements(model, data)\n",
    "\n",
    "        viz.display(q)\n",
    "        time.sleep(0.01)\n",
    "    \n",
    "    # storing the weights and x_nom\n",
    "    y_train[k] = torch.hstack((ioc.weight.flatten(), ioc.x_nom))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f71a8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.hstack((x_train_init, x_train_des)).float()\n",
    "y_train = y_train.detach().float()\n",
    "\n",
    "torch.save(x_train, \"./data/x_train4.pt\")\n",
    "torch.save(y_train, \"./data/y_train4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "693e2fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 17])\n"
     ]
    }
   ],
   "source": [
    "# x_train_loaded = torch.load(\"./data/x_train6.pt\")\n",
    "# y_train_loaded = torch.load(\"./data/y_train6.pt\")\n",
    "\n",
    "# x_train_loaded2 = torch.load(\"./data/x_train2.pt\")\n",
    "# y_train_loaded2 = torch.load(\"./data/y_train2.pt\")\n",
    "\n",
    "# x_train = torch.vstack((x_train_loaded, x_train))\n",
    "# y_train = torch.vstack((y_train_loaded, y_train))\n",
    "\n",
    "# x_train = torch.vstack((x_train_loaded2, x_train))\n",
    "# y_train = torch.vstack((y_train_loaded2, y_train))\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b98864b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.mean(y_train, 0)\n",
    "std = torch.std(y_train, 0)\n",
    "z = torch.where(std == 0) ## checking where std and mean are zero\n",
    "std[z] = 1.0\n",
    "y_train_norm = (y_train - m)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0b3c9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.8461e-01,  5.0490e-01,  5.0720e-01,  4.7971e-01,  4.9594e-01,\n",
      "         5.0086e-01,  5.0668e-01,  4.8076e-01,  4.9558e-01,  4.9826e-01,\n",
      "         4.8550e-01,  5.1397e-01,  4.8894e-01,  4.9837e-01, -8.8788e-02,\n",
      "         3.0894e-01,  3.4810e-01, -1.5215e-01,  5.5927e-01,  3.2515e-01,\n",
      "         1.5229e+00,  1.5444e+00,  7.5705e-01,  4.3441e-01,  1.2036e+00,\n",
      "         4.1824e-01,  9.8678e-01,  2.2712e-01,  1.1060e+00,  1.0396e+00,\n",
      "         1.0352e+00,  1.1821e+00,  6.2034e-01,  8.1126e-01, -2.9431e-01,\n",
      "         7.6599e-02,  4.9799e-01,  4.1930e-01, -5.1961e-02,  7.1484e-01,\n",
      "         5.8735e-01,  1.5716e+00,  1.4978e+00,  7.7605e-01,  4.5718e-01,\n",
      "         1.1891e+00,  4.2459e-01,  9.5007e-01,  1.6097e-01,  1.0546e+00,\n",
      "         9.0284e-01,  9.0470e-01,  1.1229e+00,  4.6485e-01,  7.2661e-01,\n",
      "        -3.2899e-01,  5.1465e-01,  8.1554e-01,  7.1431e-01,  4.3963e-01,\n",
      "         1.0392e+00,  1.0321e+00,  1.5923e+00,  1.3755e+00,  7.2078e-01,\n",
      "         4.3756e-01,  1.1297e+00,  4.1677e-01,  7.9903e-01,  1.6611e-01,\n",
      "         8.3110e-01,  7.4689e-01,  7.7545e-01,  9.9861e-01,  3.5436e-01,\n",
      "         4.7072e-01, -3.3615e-01,  9.0578e-01,  1.3764e+00,  1.1047e+00,\n",
      "         9.6684e-01,  1.3751e+00,  1.5458e+00,  1.6244e+00,  1.2642e+00,\n",
      "         6.9024e-01,  4.5607e-01,  1.0638e+00,  3.7528e-01,  7.1250e-01,\n",
      "         1.5594e-01,  6.1470e-01,  4.8272e-01,  5.2403e-01,  7.0157e-01,\n",
      "         8.6282e-02,  1.7023e-01, -3.4873e-01,  1.2514e+00,  1.3478e+00,\n",
      "         1.1305e+00,  1.1195e+00,  1.2954e+00,  1.2704e+00,  1.6397e+00,\n",
      "         1.0659e+00,  5.9088e-01,  4.7313e-01,  9.0717e-01,  3.6896e-01,\n",
      "         5.5080e-01,  1.4494e-01,  4.5881e-01,  2.9914e-01,  2.6589e-01,\n",
      "         5.8894e-01, -1.5287e-01, -4.6891e-02, -3.7135e-01,  5.0001e-03,\n",
      "         5.0000e-03,  5.0000e-03,  5.0000e-03,  5.0000e-03,  5.0000e-03,\n",
      "         5.0000e-03,  5.0000e-03,  5.0000e-03,  5.0000e-03,  5.0000e-03,\n",
      "         5.0000e-03,  5.0000e-03,  5.0000e-03, -5.8943e-01,  7.9768e-02,\n",
      "         4.3054e-01, -5.1155e-01,  2.0191e-01,  7.0434e-02, -1.4724e-02,\n",
      "        -6.4893e-01,  3.9890e-02,  3.8267e-01, -5.6849e-01,  1.8846e-01,\n",
      "         7.2531e-02, -4.1263e-03, -5.9687e-01,  8.1292e-02,  4.3135e-01,\n",
      "        -5.3877e-01,  1.9469e-01,  7.6868e-02, -9.2753e-03, -3.7524e-01,\n",
      "        -3.8766e-03,  2.7720e-01, -4.1662e-01,  1.6018e-01,  4.6239e-02,\n",
      "        -5.2801e-03, -5.9208e-01,  9.4064e-03,  3.4570e-01, -5.6578e-01,\n",
      "         1.7714e-01,  6.7956e-02, -1.6972e-03, -5.1594e-01,  2.9949e-02,\n",
      "         3.6472e-01, -5.2117e-01,  1.7313e-01,  7.0304e-02, -4.4519e-03,\n",
      "         3.4759e-02, -4.2101e-02, -6.8947e-03,  1.2873e-01,  5.3607e-02,\n",
      "         2.5377e-02,  3.8542e-04, -5.0745e-01, -1.3873e-02,  2.9967e-01,\n",
      "        -5.0349e-01,  1.6574e-01,  6.3224e-02,  1.7593e-03, -3.7795e-01,\n",
      "        -1.7679e-02,  2.5031e-01, -3.9785e-01,  1.4135e-01,  6.3372e-02,\n",
      "        -8.5316e-04,  3.8859e-01,  4.5984e-02, -2.8891e-01,  6.6407e-01,\n",
      "        -1.5908e-01, -2.8151e-02,  5.5976e-03, -4.1119e-01, -1.8794e-02,\n",
      "         2.3681e-01, -4.1345e-01,  1.4971e-01,  6.0030e-02,  3.9942e-03,\n",
      "        -2.2535e-01, -2.3547e-02,  1.1665e-01, -2.1600e-01,  7.8525e-02,\n",
      "         5.9900e-02,  1.5061e-03,  7.5876e-01, -5.7182e-02, -4.4247e-01,\n",
      "         5.6145e-01, -2.3283e-01, -6.9598e-02,  2.2724e-03, -3.0344e-01,\n",
      "        -1.3157e-02,  1.6733e-01, -3.0236e-01,  1.1879e-01,  5.5145e-02,\n",
      "         4.7007e-03, -4.6183e-02, -3.9014e-02, -2.6957e-02,  6.2482e-02,\n",
      "        -2.0150e-02,  2.2671e-02,  3.6803e-03]) tensor([2.9121e-01, 2.8443e-01, 2.8394e-01, 2.8264e-01, 2.9221e-01, 2.9449e-01,\n",
      "        2.9027e-01, 2.8620e-01, 2.8997e-01, 2.9108e-01, 2.9175e-01, 2.9509e-01,\n",
      "        2.9142e-01, 2.8710e-01, 1.0277e+00, 1.0813e+00, 1.0568e+00, 9.6410e-01,\n",
      "        8.7271e-01, 1.1332e+00, 7.5428e-01, 1.6669e+00, 1.4911e+00, 1.3517e+00,\n",
      "        1.4525e+00, 1.0177e+00, 1.2442e+00, 4.8778e-01, 1.6294e+00, 1.6197e+00,\n",
      "        1.6365e+00, 1.3274e+00, 1.2634e+00, 1.2942e+00, 5.1313e-01, 1.0252e+00,\n",
      "        1.1269e+00, 1.0320e+00, 9.8549e-01, 9.0969e-01, 1.1505e+00, 7.4446e-01,\n",
      "        1.6319e+00, 1.4930e+00, 1.3308e+00, 1.4606e+00, 9.9757e-01, 1.2242e+00,\n",
      "        4.9247e-01, 1.6239e+00, 1.6105e+00, 1.6458e+00, 1.4022e+00, 1.1917e+00,\n",
      "        1.3185e+00, 4.4502e-01, 1.1949e+00, 1.2217e+00, 1.1122e+00, 1.1245e+00,\n",
      "        8.3730e-01, 1.1303e+00, 7.9083e-01, 1.5893e+00, 1.4520e+00, 1.3045e+00,\n",
      "        1.4023e+00, 9.3751e-01, 1.2103e+00, 4.7622e-01, 1.5501e+00, 1.5411e+00,\n",
      "        1.5737e+00, 1.3433e+00, 1.1066e+00, 1.2257e+00, 4.0682e-01, 1.6406e+00,\n",
      "        1.5992e+00, 1.4850e+00, 1.5889e+00, 1.0127e+00, 1.2326e+00, 7.7601e-01,\n",
      "        1.5060e+00, 1.3976e+00, 1.2295e+00, 1.3564e+00, 8.4427e-01, 1.0847e+00,\n",
      "        4.6174e-01, 1.4605e+00, 1.3297e+00, 1.3563e+00, 1.2832e+00, 8.6790e-01,\n",
      "        1.0173e+00, 3.7105e-01, 1.8063e+00, 1.6082e+00, 1.5634e+00, 1.6654e+00,\n",
      "        1.1597e+00, 1.3491e+00, 7.9904e-01, 1.4643e+00, 1.2546e+00, 1.1797e+00,\n",
      "        1.2782e+00, 7.5665e-01, 9.7231e-01, 4.4436e-01, 1.4079e+00, 1.2110e+00,\n",
      "        1.1326e+00, 1.3044e+00, 6.4644e-01, 7.9299e-01, 2.9044e-01, 8.9580e-07,\n",
      "        4.9954e-07, 4.8492e-07, 7.7444e-07, 7.0153e-08, 1.5074e-07, 1.3318e-10,\n",
      "        1.8514e-07, 1.0346e-07, 8.6943e-08, 1.4649e-07, 1.7488e-08, 2.5155e-08,\n",
      "        1.2732e-08, 1.9026e+00, 1.7289e+00, 1.6452e+00, 1.6740e+00, 1.1708e+00,\n",
      "        1.3350e+00, 3.0064e-01, 1.9713e+00, 1.7756e+00, 1.6608e+00, 1.6822e+00,\n",
      "        1.1458e+00, 1.3611e+00, 2.8728e-01, 1.9462e+00, 1.8021e+00, 1.7185e+00,\n",
      "        1.6854e+00, 1.1710e+00, 1.3627e+00, 2.8194e-01, 1.7763e+00, 1.5276e+00,\n",
      "        1.4906e+00, 1.6083e+00, 9.5875e-01, 1.1048e+00, 2.4130e-01, 1.9378e+00,\n",
      "        1.7276e+00, 1.6251e+00, 1.6810e+00, 1.0883e+00, 1.3088e+00, 2.6658e-01,\n",
      "        1.9027e+00, 1.7191e+00, 1.6681e+00, 1.6804e+00, 1.0790e+00, 1.2747e+00,\n",
      "        2.4992e-01, 1.7100e+00, 1.2113e+00, 1.2408e+00, 1.4863e+00, 4.8948e-01,\n",
      "        7.5911e-01, 1.8456e-01, 1.8676e+00, 1.6386e+00, 1.5544e+00, 1.6338e+00,\n",
      "        1.0126e+00, 1.2095e+00, 2.4478e-01, 1.7965e+00, 1.5633e+00, 1.5304e+00,\n",
      "        1.5804e+00, 9.4156e-01, 1.1045e+00, 2.1540e-01, 1.9517e+00, 1.6128e+00,\n",
      "        1.5632e+00, 1.7021e+00, 9.9341e-01, 1.1856e+00, 1.2100e-01, 1.7882e+00,\n",
      "        1.5191e+00, 1.4640e+00, 1.5548e+00, 9.0843e-01, 1.0772e+00, 2.2049e-01,\n",
      "        1.6707e+00, 1.3174e+00, 1.3340e+00, 1.4462e+00, 7.2728e-01, 8.5447e-01,\n",
      "        1.7463e-01, 2.2948e+00, 2.0823e+00, 2.0207e+00, 1.9235e+00, 1.2677e+00,\n",
      "        1.5276e+00, 6.4853e-02, 1.6963e+00, 1.3627e+00, 1.3355e+00, 1.4633e+00,\n",
      "        7.7601e-01, 9.1502e-01, 1.9499e-01, 1.5706e+00, 1.1610e+00, 1.1295e+00,\n",
      "        1.3975e+00, 4.4092e-01, 6.2569e-01, 1.2772e-01])\n"
     ]
    }
   ],
   "source": [
    "print(m, std)\n",
    "torch.save(m, \"./data/mean.pt\")\n",
    "torch.save(std, \"./data/std.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66c56bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, inp_size, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(inp_size, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 512)\n",
    "        self.out = torch.nn.Linear(512, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "12768435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 17])\n",
      "The iteration number : 99999 The loss is :0.32743633\r"
     ]
    }
   ],
   "source": [
    "nn = Net(x_train.shape[1], y_train.shape[1])\n",
    "# nn.load_state_dict(torch.load(\"./models/test1\"))\n",
    "nn = nn.cuda()\n",
    "x_train = x_train.cuda()\n",
    "y_train_norm = y_train_norm.cuda()\n",
    "# y_train = y_train.cuda()\n",
    "print(x_train.shape)\n",
    "\n",
    "lr = 1e-5\n",
    "eps = int(1e5)\n",
    "batch_size = 256\n",
    "optimizer = torch.optim.Adam(nn.parameters(), lr=lr)\n",
    "loss = torch.nn.MSELoss() #torch.nn.HuberLoss()\n",
    "\n",
    "for i in range(eps):\n",
    "    \n",
    "    ind = np.random.randint(0,len(x_train), size = batch_size)\n",
    "    x_train_batch = x_train[ind]\n",
    "    y_train_batch = y_train_norm[ind]\n",
    "#     y_train_batch = y_train[ind]\n",
    "\n",
    "    y_pred = nn(x_train_batch)\n",
    "    error = loss(y_pred, y_train_batch) \n",
    "    print(\"The iteration number : \" + str(i) + \" The loss is :\" + str(error.cpu().detach().numpy()), end='\\r', flush  = True)\n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a80ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = nn.cpu()\n",
    "x_train = x_train.cpu()\n",
    "y_train_norm = y_train_norm.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d46397d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535\n",
      "tensor([0.6000, 0.4000, 0.7000])\n"
     ]
    }
   ],
   "source": [
    "k = np.random.randint(buffer_size)\n",
    "print(k)\n",
    "x_des = x_train[k]\n",
    "viz.viewer[\"box\"].set_object(g.Sphere(0.05), \n",
    "                         g.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))\n",
    "viz.viewer[\"box\"].set_transform(tf.translation_matrix(x_des[-3:].detach().numpy()))\n",
    "\n",
    "# x_des = x_train[0]\n",
    "print(x_des[-3:])\n",
    "\n",
    "pred_norm = nn(x_des)\n",
    "pred = pred_norm * std + m\n",
    "# pred = y_train[k]\n",
    "\n",
    "if not isvec:\n",
    "    ioc.weight = torch.nn.Parameter(torch.reshape(pred[0:n_vars**2], (n_vars, n_vars)))\n",
    "    ioc.x_nom = torch.nn.Parameter(pred[n_vars**2:])\n",
    "else:\n",
    "    ioc.weight = torch.nn.Parameter(pred[0:n_vars])\n",
    "    ioc.x_nom = torch.nn.Parameter(pred[n_vars:])\n",
    "\n",
    "x_pred = ioc((x_des[:-3]).detach().numpy()) \n",
    "x_pred = x_pred.detach().numpy()\n",
    "\n",
    "plt_des = np.zeros((n_col+1, 3))\n",
    "\n",
    "for i in range(n_col+1):\n",
    "    q = x_pred[3*nq*i:3*nq*i + nq]\n",
    "    dq = x_pred[3*nq*i + nq:3*nq*i + 2*nq]\n",
    "\n",
    "    pin.forwardKinematics(model, data, q, dq, np.zeros(nv))\n",
    "    pin.updateFramePlacements(model, data)\n",
    "    \n",
    "    plt_des[i] = data.oMf[f_id].translation\n",
    "\n",
    "    viz.display(q)\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5754e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419\n",
      "tensor([ 0.5000, -0.4000,  0.4000])\n"
     ]
    }
   ],
   "source": [
    "k = np.random.randint(buffer_size)\n",
    "print(k)\n",
    "x_in = x_train[k]\n",
    "x_des = x_in[-3:]\n",
    "print(x_des)\n",
    "\n",
    "viz.viewer[\"box\"].set_object(g.Sphere(0.05), \n",
    "                         g.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))\n",
    "viz.viewer[\"box\"].set_transform(tf.translation_matrix(x_des[-3:].detach().numpy()))\n",
    "\n",
    "\n",
    "for j in range(20):\n",
    "    ioc = IOC(n_col, nq, u_max, 0.05, eps = 1.0, isvec=isvec)\n",
    "    optimizer = torch.optim.Adam(ioc.parameters(), lr=lr)\n",
    "\n",
    "    \n",
    "    pred_norm = nn(x_in)\n",
    "    pred = pred_norm * std + m\n",
    "    \n",
    "    if not isvec:\n",
    "        ioc.weight = torch.nn.Parameter(torch.reshape(pred[0:n_vars**2], (n_vars, n_vars)))\n",
    "        ioc.x_nom = torch.nn.Parameter(pred[n_vars**2:])\n",
    "    else:\n",
    "        ioc.weight = torch.nn.Parameter(pred[0:n_vars])\n",
    "        ioc.x_nom = torch.nn.Parameter(pred[n_vars:])\n",
    "\n",
    "    x_pred = ioc((x_in[:-3]).detach().numpy()) \n",
    "    x_pred = x_pred.detach().numpy()\n",
    "\n",
    "\n",
    "    for i in range(n_col+1):\n",
    "        q = x_pred[3*nq*i:3*nq*i + nq]\n",
    "        dq = x_pred[3*nq*i + nq:3*nq*i + 2*nq]\n",
    "\n",
    "        pin.forwardKinematics(model, data, q, dq, np.zeros(nv))\n",
    "        pin.updateFramePlacements(model, data)\n",
    "\n",
    "        viz.display(q)\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    x_in[0:2*nq] = torch.tensor(x_pred[-2*nq:])\n",
    "#     print(x_pred[-nq:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "90413c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ...\n"
     ]
    }
   ],
   "source": [
    "torch.save(nn.state_dict(), \"./models/test1\")\n",
    "print(\"saved ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(x_pred[2*nq + 1:: 3*nq], label = \"joint torque\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19544503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,0], label = \"x_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,1], label = \"y_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078be1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,2], label = \"z_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78520f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
