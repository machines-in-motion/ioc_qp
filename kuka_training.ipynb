{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75e96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is demo for kuka reaching a desired point with diff_qp\n",
    "## Author : Avadesh Meduri\n",
    "## Date : 25/02/2022\n",
    "import time\n",
    "import numpy as np\n",
    "import pinocchio as pin\n",
    "from robot_properties_kuka.config import IiwaConfig\n",
    "\n",
    "import meshcat\n",
    "import meshcat.transformations as tf\n",
    "import meshcat.geometry as g\n",
    "\n",
    "from diff_pin_costs import DiffFrameTranslationCost\n",
    "from inverse_qp import IOC\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e67bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = IiwaConfig.buildRobotWrapper()\n",
    "model, data = robot.model, robot.data\n",
    "f_id = model.getFrameId(\"EE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f04e687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n"
     ]
    }
   ],
   "source": [
    "viz = pin.visualize.MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "viz.initViewer(open=False)\n",
    "viz.loadViewerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67693d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DiffFrameTranslationCost.apply\n",
    "\n",
    "def quadratic_loss(q_pred, x_des, nq, n_col):\n",
    "    loss = 1e2*torch.linalg.norm(dtc(q_pred[-2*nq:], model, data, f_id) - x_des)\n",
    "    loss += 5*torch.linalg.norm(q_pred[-nq:])\n",
    "    for i in range(n_col):    \n",
    "        loss += 0.8*torch.linalg.norm(dtc(q_pred[(3*i)*nq: (3*i+2)*nq], model, data, f_id) - x_des)\n",
    "        loss += 4e-3*torch.linalg.norm(q_pred[(3*i+2)*nq: (3*i+3)*nq]) # control regularization\n",
    "        loss += 2e-1*torch.linalg.norm(q_pred[(3*i+1)*nq: (3*i+2)*nq]) # velocity regularization\n",
    "        loss += 1e-1*torch.linalg.norm(q_pred[(3*i)*nq: (3*i+1)*nq]) # joint regularization\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f8db28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq = model.nq\n",
    "nv = model.nv\n",
    "q0 = [np.pi/16.0, -np.pi/16.0, 0, 0, 0, 0, 0]\n",
    "x_init = np.concatenate([q0, pin.utils.zero(model.nv)])\n",
    "\n",
    "n_col = 5\n",
    "u_max = [2.5,2.5,2.5, 1.5, 1.5, 1.5, 1.0]\n",
    "\n",
    "isvec = True\n",
    "lr = 1e-1\n",
    "max_eps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f7d8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 600\n",
    "\n",
    "x_train_init = torch.zeros((buffer_size,len(x_init)))\n",
    "x_train_des = torch.zeros((buffer_size, 3))\n",
    "\n",
    "n_vars = 3*nq*n_col + 2*nq\n",
    "if not isvec:\n",
    "    y_train = torch.zeros((buffer_size, n_vars**2 + n_vars))\n",
    "else:\n",
    "    y_train = torch.zeros((buffer_size, 2*n_vars))\n",
    "\n",
    "q_des_arr = np.array([[ 0.3009,  1.1532,  1.7729,  1.7383,  1.2195, -0.0204,  0.0593],\n",
    "                      [1.3737, 0.9711, 1.6139, 1.2188, 1.5669, 0.1236, 0.2565]])\n",
    "x_des_arr = torch.tensor([[0.5, -0.4, 0.4], [0.6, 0.4, 0.7]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c88cdfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :599/600 Iteration :73/100 loss is : 4.4090250543011525\r"
     ]
    }
   ],
   "source": [
    "for k in range(buffer_size):\n",
    "    ioc = IOC(n_col, nq, u_max, 0.05, eps = 1.0, isvec=isvec)\n",
    "    optimizer = torch.optim.Adam(ioc.parameters(), lr=lr)\n",
    "\n",
    "    if k % 12 == 0:\n",
    "        \n",
    "        x_des = x_des_arr[np.random.randint(len(x_des_arr))]\n",
    "    \n",
    "        viz.viewer[\"box\"].set_object(g.Sphere(0.05), \n",
    "                         g.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))\n",
    "        viz.viewer[\"box\"].set_transform(tf.translation_matrix(x_des.detach().numpy()))\n",
    "\n",
    "        x_init = np.zeros(2*nq)\n",
    "        x_init[0:nq] = q_des_arr[np.random.randint(len(x_des_arr))] + 0.5*2*(np.random.rand(nq) - 0.5)\n",
    "        x_init[nq:] = 0.2*2*(np.random.rand(nv) - 0.5)\n",
    "    \n",
    "    else:\n",
    "        x_init = x_pred[-2*nq:]\n",
    "\n",
    "    x_train_init[k] = torch.tensor(x_init)\n",
    "    x_train_des[k] = x_des\n",
    "    \n",
    "    i = 0\n",
    "    loss = 1000.\n",
    "    old_loss = 10000.\n",
    "    \n",
    "    while loss > 0.03 and i < max_eps and abs(old_loss - loss) > 5e-4:\n",
    "        x_pred = ioc(x_init) \n",
    "        old_loss = loss\n",
    "        loss = quadratic_loss(x_pred, x_des, nq, n_col)\n",
    "        print(\"Index :\" + str(k) + \"/\" + str(buffer_size) + \" Iteration :\" + str(i) + \"/\" + str(max_eps) +  \" loss is : \" + str(loss.detach().numpy()), end = '\\r', flush = True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "    \n",
    "    x_pred = ioc(x_init).detach().numpy()\n",
    "    for i in range(n_col+1):\n",
    "        q = x_pred[3*nq*i:3*nq*i + nq]\n",
    "        dq = x_pred[3*nq*i + nq:3*nq*i + 2*nq]\n",
    "\n",
    "        pin.forwardKinematics(model, data, q, dq, np.zeros(nv))\n",
    "        pin.updateFramePlacements(model, data)\n",
    "\n",
    "        viz.display(q)\n",
    "        time.sleep(0.01)\n",
    "    \n",
    "    # storing the weights and x_nom\n",
    "    y_train[k] = torch.hstack((ioc.weight.flatten(), ioc.x_nom))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f71a8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.hstack((x_train_init, x_train_des)).float()\n",
    "y_train = y_train.detach().float()\n",
    "\n",
    "# torch.save(x_train, \"./data/x_train4.pt\")\n",
    "# torch.save(y_train, \"./data/y_train4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "693e2fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 17])\n"
     ]
    }
   ],
   "source": [
    "# x_train_loaded = torch.load(\"./data/x_train6.pt\")\n",
    "# y_train_loaded = torch.load(\"./data/y_train6.pt\")\n",
    "\n",
    "# x_train_loaded2 = torch.load(\"./data/x_train2.pt\")\n",
    "# y_train_loaded2 = torch.load(\"./data/y_train2.pt\")\n",
    "\n",
    "# x_train = torch.vstack((x_train_loaded, x_train))\n",
    "# y_train = torch.vstack((y_train_loaded, y_train))\n",
    "\n",
    "# x_train = torch.vstack((x_train_loaded2, x_train))\n",
    "# y_train = torch.vstack((y_train_loaded2, y_train))\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b98864b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.mean(y_train, 0)\n",
    "std = torch.std(y_train, 0)\n",
    "z = torch.where(std == 0) ## checking where std and mean are zero\n",
    "std[z] = 1.0\n",
    "y_train_norm = (y_train - m)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b3c9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.9789e-01,  5.0906e-01,  4.9411e-01,  5.2565e-01,  4.9927e-01,\n",
      "         4.8936e-01,  5.1829e-01,  5.0976e-01,  4.7754e-01,  5.1149e-01,\n",
      "         4.8992e-01,  5.0393e-01,  4.9818e-01,  5.1288e-01,  2.6588e-01,\n",
      "         4.4143e-01,  4.9070e-01,  9.5353e-02,  6.7802e-01,  8.1798e-01,\n",
      "         1.6042e+00,  1.1117e+00,  6.6406e-01,  5.1755e-01,  9.5709e-01,\n",
      "         5.1776e-01,  5.6165e-01,  1.5054e-01,  7.8060e-01,  7.3431e-01,\n",
      "         6.1370e-01,  9.6133e-01,  2.3455e-01,  3.6897e-01, -3.4083e-01,\n",
      "         4.1614e-01,  6.2447e-01,  5.6671e-01,  1.6951e-01,  8.4918e-01,\n",
      "         1.0021e+00,  1.6944e+00,  1.1318e+00,  6.5938e-01,  5.4201e-01,\n",
      "         9.5775e-01,  4.9520e-01,  4.9541e-01,  9.4034e-02,  6.9876e-01,\n",
      "         6.0489e-01,  5.1736e-01,  8.9163e-01,  1.5119e-01,  2.7261e-01,\n",
      "        -3.7315e-01,  7.2622e-01,  9.8482e-01,  7.2890e-01,  6.3553e-01,\n",
      "         1.1983e+00,  1.2870e+00,  1.6883e+00,  1.0329e+00,  6.3254e-01,\n",
      "         5.5926e-01,  8.6288e-01,  4.5649e-01,  4.5288e-01,  1.0775e-01,\n",
      "         5.6779e-01,  5.0128e-01,  4.3864e-01,  6.8789e-01,  2.5407e-02,\n",
      "         1.7473e-01, -3.6687e-01,  1.0537e+00,  1.4319e+00,  1.0588e+00,\n",
      "         1.1297e+00,  1.5579e+00,  1.6457e+00,  1.6701e+00,  9.3977e-01,\n",
      "         5.8071e-01,  5.3848e-01,  8.1251e-01,  4.4539e-01,  3.6575e-01,\n",
      "         9.0525e-02,  4.0519e-01,  2.9855e-01,  3.1964e-01,  4.8480e-01,\n",
      "        -1.3016e-01, -3.0772e-02, -3.7875e-01,  1.3880e+00,  1.5974e+00,\n",
      "         1.3169e+00,  1.3502e+00,  1.6334e+00,  1.5402e+00,  1.6984e+00,\n",
      "         8.3398e-01,  5.6923e-01,  5.1429e-01,  7.4513e-01,  3.7628e-01,\n",
      "         2.6783e-01,  7.7635e-02,  3.3508e-01,  1.3733e-01,  1.8060e-01,\n",
      "         3.3895e-01, -2.4834e-01, -1.9833e-01, -3.7642e-01,  5.0000e-03,\n",
      "         5.0000e-03,  5.0000e-03,  5.0001e-03,  5.0000e-03,  5.0000e-03,\n",
      "         5.0000e-03,  5.0000e-03,  5.0000e-03,  5.0000e-03,  5.0000e-03,\n",
      "         5.0000e-03,  5.0000e-03,  5.0000e-03, -3.7095e-01,  3.5457e-02,\n",
      "         1.1286e-01, -3.1101e-01, -3.2739e-02, -4.8587e-03, -1.3435e-03,\n",
      "        -4.0203e-01,  2.8975e-02,  1.0285e-01, -3.4340e-01, -1.4112e-02,\n",
      "         2.2510e-03,  1.6086e-02, -3.8108e-01,  4.9237e-02,  1.1096e-01,\n",
      "        -3.2850e-01, -2.9538e-02,  9.0306e-04,  2.6275e-03, -2.4788e-01,\n",
      "         4.2921e-03,  5.7452e-02, -2.4028e-01,  3.0754e-03,  9.4000e-03,\n",
      "         8.2445e-03, -3.7033e-01,  2.1147e-02,  8.7861e-02, -3.4120e-01,\n",
      "        -4.3583e-03,  6.8889e-03,  1.8488e-02, -3.3146e-01,  2.9738e-02,\n",
      "         8.1948e-02, -3.1754e-01, -1.5400e-02,  7.5868e-03,  5.8066e-03,\n",
      "         2.6956e-02, -2.6719e-02,  2.3759e-02,  6.8502e-02,  3.1554e-02,\n",
      "         1.9972e-02,  7.1353e-03, -3.1749e-01,  1.1748e-02,  7.2641e-02,\n",
      "        -2.9722e-01,  9.6337e-03,  1.3866e-02,  1.9184e-02, -2.5258e-01,\n",
      "        -1.7804e-03,  5.0083e-02, -2.3455e-01, -1.2834e-04,  1.6497e-02,\n",
      "         5.7951e-03,  2.9448e-01,  3.8691e-03, -2.6681e-02,  3.5387e-01,\n",
      "         4.7986e-02, -2.1344e-02,  6.8120e-03, -2.5865e-01,  6.0335e-03,\n",
      "         6.0584e-02, -2.3707e-01,  2.6205e-02,  1.9106e-02,  1.9050e-02,\n",
      "        -1.5668e-01, -3.1125e-02,  2.8602e-02, -1.1790e-01,  4.9263e-03,\n",
      "         1.6263e-02,  5.8532e-03,  4.7779e-01,  3.0371e-02, -7.8100e-02,\n",
      "         4.2286e-01,  6.0402e-02,  1.0867e-02,  7.9773e-03, -1.8855e-01,\n",
      "        -1.3827e-03,  5.7870e-02, -1.6269e-01,  3.5820e-02,  2.1145e-02,\n",
      "         2.0129e-02, -2.9790e-02, -3.6620e-02,  1.5090e-02,  2.1261e-02,\n",
      "         1.6267e-03,  6.7389e-03,  6.1455e-03]) tensor([2.8943e-01, 2.9580e-01, 2.9157e-01, 2.8924e-01, 2.9177e-01, 2.9560e-01,\n",
      "        2.8672e-01, 2.9546e-01, 2.8462e-01, 2.8332e-01, 2.8305e-01, 2.8960e-01,\n",
      "        2.8251e-01, 2.8762e-01, 1.1676e+00, 1.0612e+00, 9.7549e-01, 9.7108e-01,\n",
      "        8.6787e-01, 1.2554e+00, 7.6412e-01, 1.5037e+00, 1.2951e+00, 1.2554e+00,\n",
      "        1.3611e+00, 9.0004e-01, 1.1360e+00, 4.7423e-01, 1.4911e+00, 1.5451e+00,\n",
      "        1.5042e+00, 1.3535e+00, 1.1548e+00, 1.2307e+00, 4.4722e-01, 1.1223e+00,\n",
      "        1.0492e+00, 9.6581e-01, 9.8479e-01, 8.6577e-01, 1.2899e+00, 7.7585e-01,\n",
      "        1.4928e+00, 1.3098e+00, 1.2391e+00, 1.3427e+00, 8.7070e-01, 1.1165e+00,\n",
      "        4.3632e-01, 1.5085e+00, 1.5045e+00, 1.5056e+00, 1.3881e+00, 1.0955e+00,\n",
      "        1.2147e+00, 3.8059e-01, 1.2131e+00, 1.1520e+00, 1.0450e+00, 1.0991e+00,\n",
      "        7.5328e-01, 1.2466e+00, 7.5448e-01, 1.4413e+00, 1.2687e+00, 1.2282e+00,\n",
      "        1.2838e+00, 8.2727e-01, 1.1188e+00, 4.4338e-01, 1.4692e+00, 1.4805e+00,\n",
      "        1.4434e+00, 1.3180e+00, 9.6471e-01, 1.1611e+00, 3.7745e-01, 1.5067e+00,\n",
      "        1.4203e+00, 1.2871e+00, 1.4856e+00, 8.9063e-01, 1.2127e+00, 7.9764e-01,\n",
      "        1.3856e+00, 1.2048e+00, 1.1871e+00, 1.2169e+00, 7.3401e-01, 1.0244e+00,\n",
      "        4.4265e-01, 1.4001e+00, 1.2836e+00, 1.3157e+00, 1.2505e+00, 7.5692e-01,\n",
      "        9.4158e-01, 3.3096e-01, 1.6550e+00, 1.5112e+00, 1.4466e+00, 1.5340e+00,\n",
      "        9.9886e-01, 1.2389e+00, 7.7425e-01, 1.3279e+00, 1.1087e+00, 1.1031e+00,\n",
      "        1.1728e+00, 6.9485e-01, 8.9369e-01, 4.5642e-01, 1.3423e+00, 1.1245e+00,\n",
      "        1.0943e+00, 1.2081e+00, 5.4467e-01, 7.1529e-01, 2.9387e-01, 8.9294e-07,\n",
      "        5.9234e-07, 5.5862e-07, 7.3681e-07, 5.6967e-08, 1.5710e-07, 1.0232e-10,\n",
      "        2.0573e-07, 1.5188e-07, 1.2912e-07, 1.6747e-07, 2.3862e-08, 4.3081e-08,\n",
      "        1.8314e-08, 1.6695e+00, 1.5202e+00, 1.4467e+00, 1.4984e+00, 9.4677e-01,\n",
      "        1.1108e+00, 2.5373e-01, 1.7214e+00, 1.5532e+00, 1.4631e+00, 1.5127e+00,\n",
      "        9.3964e-01, 1.1224e+00, 2.3643e-01, 1.7043e+00, 1.5771e+00, 1.4999e+00,\n",
      "        1.5191e+00, 9.5449e-01, 1.1216e+00, 2.2774e-01, 1.5476e+00, 1.3224e+00,\n",
      "        1.3158e+00, 1.4102e+00, 7.6317e-01, 9.5511e-01, 1.8928e-01, 1.6911e+00,\n",
      "        1.5092e+00, 1.4298e+00, 1.5091e+00, 8.9750e-01, 1.0840e+00, 2.1385e-01,\n",
      "        1.6559e+00, 1.5005e+00, 1.4444e+00, 1.5033e+00, 8.8101e-01, 1.0671e+00,\n",
      "        1.9508e-01, 1.5009e+00, 1.1429e+00, 1.2352e+00, 1.2453e+00, 3.6858e-01,\n",
      "        6.8650e-01, 1.4634e-01, 1.6300e+00, 1.4304e+00, 1.3841e+00, 1.4468e+00,\n",
      "        8.2612e-01, 1.0259e+00, 1.9515e-01, 1.5685e+00, 1.3747e+00, 1.3670e+00,\n",
      "        1.3738e+00, 7.4656e-01, 9.6184e-01, 1.6881e-01, 1.6904e+00, 1.3931e+00,\n",
      "        1.3810e+00, 1.5199e+00, 7.9119e-01, 9.9716e-01, 1.1750e-01, 1.5639e+00,\n",
      "        1.3278e+00, 1.3083e+00, 1.3628e+00, 7.2899e-01, 9.2721e-01, 1.7943e-01,\n",
      "        1.4681e+00, 1.1806e+00, 1.2247e+00, 1.2532e+00, 5.4721e-01, 7.3680e-01,\n",
      "        1.4716e-01, 2.0004e+00, 1.8279e+00, 1.7658e+00, 1.7109e+00, 1.0423e+00,\n",
      "        1.2546e+00, 6.8541e-02, 1.4812e+00, 1.2071e+00, 1.2211e+00, 1.2757e+00,\n",
      "        6.0613e-01, 7.8455e-01, 1.6234e-01, 1.3812e+00, 1.0284e+00, 1.0800e+00,\n",
      "        1.1702e+00, 3.3759e-01, 5.2578e-01, 1.1034e-01])\n"
     ]
    }
   ],
   "source": [
    "print(m, std)\n",
    "torch.save(m, \"./data/mean.pt\")\n",
    "torch.save(std, \"./data/std.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66c56bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, inp_size, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(inp_size, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 512)\n",
    "        self.out = torch.nn.Linear(512, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12768435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 17])\n",
      "The iteration number : 29999 The loss is :0.26960125\r"
     ]
    }
   ],
   "source": [
    "nn = Net(x_train.shape[1], y_train.shape[1])\n",
    "nn.load_state_dict(torch.load(\"./models/test1\"))\n",
    "# nn = nn.cuda()\n",
    "# x_train = x_train.cuda()\n",
    "# y_train_norm = y_train_norm.cuda()\n",
    "# y_train = y_train.cuda()\n",
    "print(x_train.shape)\n",
    "\n",
    "lr = 1e-5\n",
    "eps = int(3e4)\n",
    "batch_size = 256\n",
    "optimizer = torch.optim.Adam(nn.parameters(), lr=lr)\n",
    "loss = torch.nn.L1Loss() #torch.nn.MSELoss() #torch.nn.HuberLoss()\n",
    "\n",
    "for i in range(eps):\n",
    "    \n",
    "    ind = np.random.randint(0,len(x_train), size = batch_size)\n",
    "    x_train_batch = x_train[ind]\n",
    "    y_train_batch = y_train_norm[ind]\n",
    "#     y_train_batch = y_train[ind]\n",
    "\n",
    "    y_pred = nn(x_train_batch)\n",
    "    error = loss(y_pred, y_train_batch) \n",
    "    print(\"The iteration number : \" + str(i) + \" The loss is :\" + str(error.cpu().detach().numpy()), end='\\r', flush  = True)\n",
    "    optimizer.zero_grad()\n",
    "    error.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a80ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = nn.cpu()\n",
    "x_train = x_train.cpu()\n",
    "y_train_norm = y_train_norm.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d46397d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535\n",
      "tensor([ 0.5000, -0.4000,  0.4000])\n"
     ]
    }
   ],
   "source": [
    "k = np.random.randint(buffer_size)\n",
    "print(k)\n",
    "x_des = x_train[k]\n",
    "viz.viewer[\"box\"].set_object(g.Sphere(0.05), \n",
    "                         g.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))\n",
    "viz.viewer[\"box\"].set_transform(tf.translation_matrix(x_des[-3:].detach().numpy()))\n",
    "\n",
    "# x_des = x_train[0]\n",
    "print(x_des[-3:])\n",
    "\n",
    "pred_norm = nn(x_des)\n",
    "pred = pred_norm * std + m\n",
    "# pred = y_train[k]\n",
    "\n",
    "if not isvec:\n",
    "    ioc.weight = torch.nn.Parameter(torch.reshape(pred[0:n_vars**2], (n_vars, n_vars)))\n",
    "    ioc.x_nom = torch.nn.Parameter(pred[n_vars**2:])\n",
    "else:\n",
    "    ioc.weight = torch.nn.Parameter(pred[0:n_vars])\n",
    "    ioc.x_nom = torch.nn.Parameter(pred[n_vars:])\n",
    "\n",
    "x_pred = ioc((x_des[:-3]).detach().numpy()) \n",
    "x_pred = x_pred.detach().numpy()\n",
    "\n",
    "plt_des = np.zeros((n_col+1, 3))\n",
    "\n",
    "for i in range(n_col+1):\n",
    "    q = x_pred[3*nq*i:3*nq*i + nq]\n",
    "    dq = x_pred[3*nq*i + nq:3*nq*i + 2*nq]\n",
    "\n",
    "    pin.forwardKinematics(model, data, q, dq, np.zeros(nv))\n",
    "    pin.updateFramePlacements(model, data)\n",
    "    \n",
    "    plt_des[i] = data.oMf[f_id].translation\n",
    "\n",
    "    viz.display(q)\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5754e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n",
      "tensor([0.6000, 0.4000, 0.7000])\n"
     ]
    }
   ],
   "source": [
    "k = np.random.randint(buffer_size)\n",
    "print(k)\n",
    "x_in = x_train[k]\n",
    "x_des = x_in[-3:]\n",
    "print(x_des)\n",
    "\n",
    "viz.viewer[\"box\"].set_object(g.Sphere(0.05), \n",
    "                         g.MeshLambertMaterial(\n",
    "                             color=0xff22dd,\n",
    "                             reflectivity=0.8))\n",
    "viz.viewer[\"box\"].set_transform(tf.translation_matrix(x_des[-3:].detach().numpy()))\n",
    "\n",
    "\n",
    "for j in range(20):\n",
    "    ioc = IOC(n_col, nq, u_max, 0.05, eps = 1.0, isvec=isvec)\n",
    "    optimizer = torch.optim.Adam(ioc.parameters(), lr=lr)\n",
    "\n",
    "    \n",
    "    pred_norm = nn(x_in)\n",
    "    pred = pred_norm * std + m\n",
    "    \n",
    "    if not isvec:\n",
    "        ioc.weight = torch.nn.Parameter(torch.reshape(pred[0:n_vars**2], (n_vars, n_vars)))\n",
    "        ioc.x_nom = torch.nn.Parameter(pred[n_vars**2:])\n",
    "    else:\n",
    "        ioc.weight = torch.nn.Parameter(pred[0:n_vars])\n",
    "        ioc.x_nom = torch.nn.Parameter(pred[n_vars:])\n",
    "\n",
    "    x_pred = ioc((x_in[:-3]).detach().numpy()) \n",
    "    x_pred = x_pred.detach().numpy()\n",
    "\n",
    "\n",
    "    for i in range(n_col+1):\n",
    "        q = x_pred[3*nq*i:3*nq*i + nq]\n",
    "        dq = x_pred[3*nq*i + nq:3*nq*i + 2*nq]\n",
    "\n",
    "        pin.forwardKinematics(model, data, q, dq, np.zeros(nv))\n",
    "        pin.updateFramePlacements(model, data)\n",
    "\n",
    "        viz.display(q)\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    x_in[0:2*nq] = torch.tensor(x_pred[-2*nq:])\n",
    "#     print(x_pred[-nq:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90413c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ...\n"
     ]
    }
   ],
   "source": [
    "torch.save(nn.state_dict(), \"./models/test1\")\n",
    "print(\"saved ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(x_pred[2*nq + 1:: 3*nq], label = \"joint torque\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19544503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,0], label = \"x_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,1], label = \"y_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078be1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_des = np.array(plt_des)\n",
    "plt.plot(plt_des[:,2], label = \"z_pos\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78520f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
